# -*- coding: utf-8 -*-
"""Deliverable_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q47OvaClXuozgixOcbkFvPK_1i0AAA6g
"""

!pip install numpy
!pip install pandas
!pip install matplotlib
!pip install scipy
!pip install sklearn

import numpy as np
import pandas as pd
import sklearn as sk
import matplotlib.pyplot as plt
import scipy as sp


from pandas import read_csv
from pandas.plotting import scatter_matrix
from matplotlib import pyplot
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error
from sklearn.metrics.cluster import adjusted_rand_score


from sklearn import datasets
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV

from sklearn.metrics import f1_score
import sys
import warnings

import pprint
#pp = pprint.PrettyPrinter(indent=4)

"""# New Section"""

import sys
print('Python: {}'.format(sys.version))
# scipy
import scipy
print('scipy: {}'.format(scipy.__version__))
# numpy
import numpy
print('numpy: {}'.format(numpy.__version__))
# matplotlib
import matplotlib
print('matplotlib: {}'.format(matplotlib.__version__))
# pandas
import pandas
print('pandas: {}'.format(pandas.__version__))
# scikit-learn
import sklearn
print('sklearn: {}'.format(sklearn.__version__))

dataset = pd.read_csv('/content/heart.csv')
#https://www.kaggle.com/johnsmith88/heart-disease-dataset
print (dataset)
print(dataset.shape)
print(dataset.head(10))

"""# New Section"""

print(dataset.describe())

#Notice that the dataset is balanced!!
print(dataset.groupby('target').size())

dataset.hist(figsize=(15,15))
pyplot.show()

scatter_matrix(dataset, figsize  = [15, 15], s=0.2)
pyplot.show()

train_ratio = 0.80

array = dataset.values
X = array[:,0:4]
y = array[:,4]

X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=1 - train_ratio)

array_values = dataset.values
X_values = array[:,0:4]
y_values = array[:,4]

bootstrap = [True, False]
number_of_trees = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
max_features = ['auto', 'sqrt']
split_min_samples = [2, 5, 10]
leaf_min_samples = [1, 2, 4]

random_grid = {'bootstrap': bootstrap,
               'n_estimators': number_of_trees,
               'max_features': max_features,
               'min_samples_split': split_min_samples,
               'min_samples_leaf': leaf_min_samples,
               }

rf = RandomForestClassifier()
rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 90, cv = 3, verbose=2, random_state=40, n_jobs = -1)
rf_random.fit(X_train, Y_train)

rf_random.best_params_

y_pred=rf_random.predict(X_test)

print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))

confusion_matrix(Y_test, y_pred)

warnings.filterwarnings('ignore')

print("\t\t    F1 score: \n\t   **********************************\n")
print(f1_score(Y_test, y_pred, average='macro'))
print("\t\t    Accuracy score: \n\t   **********************************\n")
print(accuracy_score(Y_test, y_pred),"\n")
print("\t\t    Confusion Matrix: \n\t   **********************************\n")

print(confusion_matrix(Y_test, y_pred),"\n")
print("\t\t   Classification report: \n\t    **********************************\n")
print (classification_report(Y_test, y_pred))

print("\t\t    Mean Squared Error: \n\t   **********************************\n")
print (mean_squared_error(Y_test, y_pred))

print("\t\t    Rand Score: \n\t   **********************************\n")
print(adjusted_rand_score(Y_test, y_pred))

print('Parameters currently in use:\n')
print(rf_random.get_params())

import pickle
pickle.dump(rf_random, open('weights/weights', 'wb'))